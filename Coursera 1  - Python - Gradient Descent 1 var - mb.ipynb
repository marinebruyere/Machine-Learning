{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open('Desktop\\ex1data1.txt') as inputfile:\n",
    "    for line in inputfile:\n",
    "        results.append(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Il y a au total m observations dans la matrix M.\\nOn utilise la colonne X et pas M pour ne pas compter X et Y \\ncar la commande size nous donne le nombre de chiffre et pas le nomber de lignes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = numpy.array(results)\n",
    "M = M.astype('float')\n",
    "\"\"\"Le fichier Result est utilisé pour créer la matric M\"\"\"\n",
    "X = M[:,0]\n",
    "\"\"\"La premiere colonne de la matrix M correspond à la valeur X\"\"\"\n",
    "Y = M[:,1]\n",
    "\"\"\"La deuxieme colonne de la matrix M correspond à la valeur Y\"\"\"\n",
    "m = numpy.size(X)\n",
    "\"\"\"Il y a au total m observations dans la matrix M.\n",
    "On utilise la colonne X et pas M pour ne pas compter X et Y \n",
    "car la commande size nous donne le nombre de chiffre et pas le nomber de lignes\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LM(theta0, theta1, X):\n",
    "    return theta0 + theta1 * X\n",
    "# on définit le modèle linéaire comme étant \n",
    "# une fonction des thetas, predis plus tard, \n",
    "# et une fonction de X, la colonne définie a l'étape précédente\n",
    "# on stocke l'expression du modèle linéaire associée à la variable LM\n",
    "# LM renvoiera le calcul de theta0 + theta1 * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(theta1, theta0, X, Y):\n",
    "    totloss = 0\n",
    "    m = numpy.size(X)\n",
    "    for i in range (0, m) :\n",
    "      #  print(i)\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "      #  print(totloss)\n",
    "        totloss = totloss + ((theta1*x+theta0) - y)**2\n",
    "    return totloss/(2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(theta1, theta0, X, Y):\n",
    "    totloss = 0\n",
    "    m = numpy.size(X)\n",
    "    for i in range (0, m) :\n",
    "      #  print(i)\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "      #  print(totloss)\n",
    "        totloss = numpy.sum(((theta1*x+theta0) - y)**2)\n",
    "    return totloss/(2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17459100011597936"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss (1, 1, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(theta1, theta0, X, Y):\n",
    "    totloss = 0\n",
    "    m = numpy.size(X)\n",
    "    loss_to_sum = (Y - (theta1*X+theta0))**2\n",
    "    loss = loss_to_sum.sum()\n",
    "    return loss/(2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.266520491383504"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss (1, 1, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(theta1, theta0, X, Y):\n",
    "    totloss = 0\n",
    "    m = numpy.size(X)\n",
    "    totloss = numpy.sum(((theta1*X+theta0) - Y)**2)\n",
    "    return totloss/(2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.266520491383504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss (1, 1, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, Y):\n",
    "    theta0 = 0 #la constante de ma ligne\n",
    "    theta1 = 0 #la pente de ma ligne\n",
    "    learning_rate = 0.01 #rapidité pour se rapprocher de la convergence\n",
    "    epsi = 0.0001 #le résidu maximum qu'on veut trouver\n",
    "    max_iters = 1500 #le nombre d'itération maximale\n",
    "    \n",
    "    m = numpy.size(X)\n",
    "    \n",
    "    iters = 0     #le nombre d'itération\n",
    "    res = loss(theta1, theta0, X, Y)\n",
    "    delta_theta0 = 0 \n",
    "    delta_theta1 = 0\n",
    "    \n",
    "    while res > epsi :     # je veux minimiser mon résidu < epsi\n",
    "        iters+=1\n",
    "        res = loss(theta1, theta0, X, Y)\n",
    "        \n",
    "        for i in range(0, m) :\n",
    "            x = X[i]\n",
    "            y = Y[i]\n",
    "            yp = theta1*x + theta0\n",
    "            delta_theta0 +=  (1/m) * (yp - y)    \n",
    "            delta_theta1 += (1/m) * ((yp - y)*x)\n",
    "        \n",
    "        theta0 = theta0 - (learning_rate * delta_theta0)\n",
    "        theta1 = theta1 - (learning_rate * delta_theta1)\n",
    "            \n",
    "        if iters > max_iters :\n",
    "            print (\"maximum itération dépassé\")\n",
    "            break\n",
    "    return (res , theta0, theta1, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum itération dépassé\n",
      "(5.063781240184499, -1.5661506325895775, 0.22804570114273037, 1501)\n"
     ]
    }
   ],
   "source": [
    "print (gradient(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, Y):\n",
    "    theta0 = 0 #la constante de ma ligne\n",
    "    theta1 = 0 #la pente de ma ligne\n",
    "    learning_rate = 0.01 #rapidité pour se rapprocher de la convergence\n",
    "    epsi = 0.0001 #le résidu maximum qu'on veut trouver\n",
    "    max_iters = 1500 #le nombre d'itération maximale\n",
    "    \n",
    "    m = numpy.size(X)\n",
    "    \n",
    "    iters = 0     #le nombre d'itération\n",
    "    res = loss(theta1, theta0, X, Y)\n",
    "    \n",
    "    while res < epsi :     # je veux minimiser mon résidu < epsi\n",
    "        iters+=1\n",
    "        delta_theta0 = numpy.sum((1/m) * ((theta1*X + theta0) - Y))    \n",
    "        delta_theta1 = numpy.sum((1/m) * (((theta1*X + theta0) - Y)*X))\n",
    "        \n",
    "        theta0 = theta0 - (learning_rate * delta_theta0)\n",
    "        theta1 = theta1 - (learning_rate * delta_theta1)\n",
    "        res = loss(theta1, theta0, X, Y)\n",
    "        \n",
    "        if iters > max_iters :\n",
    "            print (\"maximum itération dépassé\")\n",
    "            break\n",
    "    return (res , theta0, theta1, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.072733877455676, 0, 0, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, Y):\n",
    "    theta0 = 0 #la constante de ma ligne\n",
    "    theta1 = 0 #la pente de ma ligne\n",
    "    learning_rate = 0.01 #rapidité pour se rapprocher de la convergence\n",
    "    epsi = 0.0001 #le résidu maximum qu'on veut trouver\n",
    "    max_iters = 1500 #le nombre d'itération maximale\n",
    "    \n",
    "    m = numpy.size(X)\n",
    "    \n",
    "    iters = 0     #le nombre d'itération\n",
    "    res = loss(theta1, theta0, X, Y)\n",
    "    delta_theta0 = 0 \n",
    "    delta_theta1 = 0\n",
    "    \n",
    "    while res > epsi :     # je veux minimiser mon résidu < epsi\n",
    "        iters+=1\n",
    "        res = loss(theta1, theta0, X, Y)\n",
    "        \n",
    "        delta_theta0 = numpy.sum((1/m) * ((theta1*X + theta0) - Y))    \n",
    "        delta_theta1 = numpy.sum((1/m) * (((theta1*X + theta0) - Y)*X))\n",
    "        \n",
    "        theta0 = theta0 - (learning_rate * delta_theta0)\n",
    "        theta1 = theta1 - (learning_rate * delta_theta1)\n",
    "            \n",
    "        if iters > max_iters :\n",
    "            print (\"maximum itération dépassé\")\n",
    "            break\n",
    "    return (res , theta0, theta1, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum itération dépassé\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.483388256587726, -3.6307700095575344, 1.166410427898432, 1501)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
